summary(fit3)
cor(mtcars$cyl,mtcars$disp)
qt(.93, df= 29)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(x,y)
fit <- glm(y~x, poison)
fit <- glm(y~x, poisson)
summary(fit)
?seq()
?pi
x
y
knots <- 0
splineterms <- sapply(knots, function(knot)(x>knot)*(x-knot))
splineterms
xmat <- cbin(1,x,splineTerms)
xmat <- cbind(1,x,splineTerms)
xmat <- cbind(1,x,splineterms)
yhat <- predict(lm(y~xmat))
plot(x,y)
lines(x,yhat,col = 'red')
summary(lm(y~xmat))
99/(999+99)
library(AppliedPredictiveModeling)
library(caret)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
pred <- grep("^IL" names(testing),value=TRUE)
pred <- grep("^IL", names(testing),value=TRUE)
pred
sub <- subset(training, select=c(diagnosis, pred))
head(training$diagnosis)
pred[1,]
pred[1,]
pred
sub <- subset(training, select=pred)
head(sub)
length(pred)
pred
sub <- training$diagnosis
head(sub)
tail(sub)
library(dplyr)
sub <- subset(training, select=pred)
dim(sub)
dim(training)
sub <- mutate(sub, diagnosis = training$diagnosis)
head(sub)
head(sub$diagnosis)
class(sub$diagnosis)
class(c(sub))
c(sub)
class(sub)
class(trainig$diagnosis)
class(training$diagnosis)
levels(training$diagnosis)
sub <- subset(training, select=c(diagnosis, pred))
pred[]
sub <- subset(training, select=c(diagnosis, pred[]))
pred <- grep("^IL|diagnosis", names(testing),value=TRUE)
pred
sub <- subset(training, select=pred)
head(sub)
head(sub[,-1])
head(sub,-13)
head(sub[,-13])
presub <- preProcess(sub[,-1],method="pca",threh=.8)
trpresub <- predict(presub, sub[,-1])
presubfit <- train(sub$diagnosis~., method="glm",data=trpresub)
trsub <- train(diagnosis~.,method="glm",data=sub)
library(ggplot2)
trsub <- train(diagnosis~.,method="glm",data=sub)
library(caret)
trsub <- train(diagnosis~.,method="glm",data=sub)
library(caret)
trsub <- train(diagnosis~.,method="glm",data=sub)
trsub <- train(diagnosis~.,method="glm",data=sub)
?uninstall.packages()
libarary(caret)
library(caret)
remove.package(caret)
?remove.package()
?install.package()
?ls
?remove.packages()
remove.packages(caret)
utils:::menuInstallPkgs()
q()
?colSums()
8/6
?matrix()
100/16
7/8
?predict()
?show()
?mean()
?dgamma()
?mean()
?colSums()
devtools::install_github('rstudio/shinyapps')
getwd()
shinyapps::setAccountInfo(name='uperera', token='95F0F148C4830F9C5900FA298C292A3A', secret='GXvH4k+ErX9ZXNmYd0xIZUw1PK0UJ+aAAp2Vit1Q')
library(shinyapps)
shinyapps::deployApp('path/to/your/app')
library(rsconnect)
x <- c(7921,5184,8836,4761)
mean(x)
(4761-6675.5)/(8836-4761)
?svd
?transpose
?matrix
data(ozone)
library(ElemStatLearn)
data(ozone)
dim(ozone)
dim(ozone)[1]
sample(1:dim(ozone)[1], replace = t)
sample(1:dim(ozone)[1], replace = T)
test <- data.frame(2 2 3; 2 3 3; 4 1 4)
test <- matrix(2 2 3; 2 3 3; 4 1 4)
test <- data.frame(2, 2, 3; 2, 3, 3; 4, 1, 4)
test <- data.frame(2, 2, 3)
rbind(test, 1,2,4)
rbind(test, 1 2 3)
for i in 1:ncol(test){}
for i in 1:ncol(test){ lapply(test,function(y,col) y[,col],col =i)}
for i in (1:ncol(test)){ lapply(test,function(y,col) y[,col],col =i)}
for (i in 1:ncol(test)){ lapply(test,function(y,col) y[,col],col =i)}
for (i in 1:nrow(test)){ lapply(test,function(y,col) y[,col],col =i)}
lapply(test,function(y,col) y[,col],col =2)
?lapply
?stripWhitespace
?tm_map
tm_map()
library(tmap)
tm_map()
library(tm)
tm_map()
?tm_map
?tm_map()
?tm_map()
?TermDocMatrix
TermDocMatrix()
TermDocumentMatrix()
?rbinom
?rbinom()
library(RWeka)
library(RWeka)
Sys.getenv("JAVA_HOME")
library(rJava)
if(Sys.getenv("JAVA_HOME")!=""){
Sys.setenv(JAVA_HOME="")
}
library(rJava)
system("java -version")
system("java -version")
?sort
?tmMap
?tm_map
library(tm)
?tmMap
?tmMap()
?tm_map
tm_map("I want to Test thiS", FUN=tmTolower)
library(tmMap)
library(tmmap)
?tm_map()
phr <- "I need to Test"
cps <- Vcorpus(VectorSource(phr))
cps <- VCorpus(VectorSource(phr))
tm_map(cps,content_transformer(tolower))
inspect(cps[[1]])
inspect(cps[1]])
inspect(cps[1])
TextRepository(cps)
cps[[1]]
cps[1]
cps[[1]]
show(cps)
show(cps[[1]])
Content(cps[[1]])
cps[[1:1]]
next <- "I bought a case of"
next <- 3
next = 3
j <- 3
rm(j)
nextdw <- "I bought a case of"
grep("[.*]+ +[.*]+ +[.*]$", nextwd, value = TRUE)
nextwd
grep("[.*]+ +[.*]+ +[.*]$", nextdw, value = TRUE)
grep(".*+ +$, nextwd, value = TRUE")
grep(".*+ +$, nextdw, value = TRUE")
grep(".*+ +$" , nextdw, value = TRUE")
)
grep(".*+ +$" , nextdw, value = TRUE)
grep("(.*)+ +$" , nextdw, value = TRUE)
grep("(.*)+ +(.*)$" , nextdw, value = TRUE)
gsub("(.*)+ +(.*)$" ,"\\1", nextdw)
gsub(" +(.*)+ +(.*)$" ,"\\1", nextdw)
gsub(" +(.*)+ +(.*)$" ,"\\1", 123)
gsub(" +[a-z*]{3}$","\\1", nextwd)
gsub(" +[a-z*]{3}$","\\1", nextdw)
gsub(" +[a-z*]{3}$","\\2", nextdw)
gsub("[a-z*]{3}$","\\2", nextdw)
gsub(" [a-z*]{3}$","\\2", nextdw)
gsub(" [a-z*]{5}$","\\2", nextdw)
gsub(" [a-z*]{6}$","\\2", nextdw)
gsub(" [a-z*]{2} [a-z*]$","\\2", nextdw)
gsub(" [a-z*]{2} [a-z*]$","\\", nextdw)
?gsub
close(con)
gsub("uthpala", "\\1", "I am uthpala perera")
nextdw
nextwd[grep("bought",nextwd)]
nextdw[grep("bought",nextdw)]
grep("(a-z){3}", "ap" value=T)
grep("(.*)", "12345",value=T)
grep(" (.*)", "12345",value=T)
grep(" (.*)$", " 12345",value=T)
grep(" (.*)$", " 12345 ",value=T)
grep(" (.*)$", " 12345 abc",value=T)
grep(" (a-z*)$", " 12345 abc",value=T)
grep(" ((a-z)*)$", " 12345 abc",value=T)
grep(" (a-z){1,})$", " 12345 abc",value=T)
grep(" (a-z){1,})$", " abc",value=T)
grep(" [a-z]{1,})$", " abc",value=T)
grep(" [a-z]{1,}$", " abc",value=T)
grep(" [a-z]{1,}$", "  abc",value=T)
grep("[a-z]{1,} [a-z]{1,}$", "  abc",value=T)
grep("[a-z]{1,} [a-z]{1,}$", "abc abc",value=T)
grep("[a-z]{1,} [a-z]{1,}$", "abc  abc",value=T)
grep("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "abc abc",value=T)
grep("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "abc abc abc",value=T)
grep("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "abc abc abc a",value=T)
grep("[a-z]{1,} [a-z]{1,} $[a-z]{1,}", "abc abc abc a",value=T)
grep("[a-z]{1,} [a-z]{1,} $[a-z]{1,}", "abc abc abc",value=T)
grep("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "abc abc abc",value=T)
grep("^[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "abc abc abc",value=T)
grep("^[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "abc abc abc a",value=T)
grep("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "abc abc abc a",value=T)
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", \\1, "abc abc abc a")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\1", "abc abc abc a")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\1", "ura abc abc a")
sub("^[[a-z]{1,} [a-z]{1,} [a-z]{1,}$]", "\\1", "ura abc abc a")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\1", "ura abc abc a")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\2", "ura abc abc a")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\3", "ura abc abc a")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\3", "ura abc abc a amma")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\1", "ura abc abc a amma")
sub("[a-z]{1,} [a-z]{1,} [a-z]{1,}$", "\\1", "ura abc abc a amma")
pat <- "[a-z]{1,} [a-z]{1,} [a-z]{1,}$"
sub(pat,\\1, newdw[grep(pat,newdw)])
sub(pat,"\\1", newdw[grep(pat,newdw)])
sub(pat,"\\1", nextdw[grep(pat,nextdw)])
nextdw
nextdw[grep(pat,nextdw)
]
sub(?pat,"\\1", nextdw[grep(pat,nextdw)])
sub("[0-9]+", "\\1", "aaa12xxxx")
?str_extract
str_extract(nextdw,pat)
library(stringr)
str_extract(nextdw,pat)
?sample
test
test <- "Sigur RÃ³s have never been a â<U+0080><U+0098>conventional rock bandâ<U+0080><U+0099>. Challenging the listener"
tcp <- VCorpus(VectorSource(test))
as.character(tcp[[1]])
tcp <- tm_map(tcp,content_transformer(function(x) iconv(x, to="ASCII", sub=" "))))
tcp <- tm_map(tcp,content_transformer(function(x) iconv(x, to="ASCII", sub=" ")))
as.character(tcp[[1]])
con <- file("c:/temp/coursework-capstone/final/en_US/en_US.blogs.txt","r")
tcp <- readLines(con,5)
close(con)
test <- VCorpus(VectorSource(tcp))
as.character(test[[1]])
as.character(test[[1:5]])
as.character(test[[2]])
as.character(test[1:5])
as.character(test[[5]])
as.character(test[[1:5]])
as.character(test[[1:4]])
as.character(test[[4]])
as.character(test[[2]])
as.character(test[[3]])
as.character(test[[1]])
as.character(test[[4]])
test <- tm_mp(test,content_transformer(function(x) iconv(x, to="ASCII", sub=" ")) )
test <- tm_map(test,content_transformer(function(x) iconv(x, to="ASCII", sub=" ")) )
as.character(test[[1]])
?VCorpus
test <- VCorpus(VectorSource("I am testing This now OK", ignore.case=TRUE))
var <- "The guy in front of me just bought a pound of bacon, a bouquet, and a case of"
pat <-"^[a=z|A-Z]{1,} "
gsub(pat, "/s/?" var)
gsub(pat, "/s/\\1" var)
gsub(pat, "/s/?" ,var)
gsub(pat, "/s/\\1" ,var)
gsub(pat, "/s/\1" ,var)
gsub(pat, "what\1" ,var)
gsub(pat, "what\\1" ,var)
grep(pat, var,value=T)
pat
pat <-"^[a-z|A-Z]{1,} "
grep(pat, var,value=T)
gsub(pat, "what\\1" ,var)
gsub(pat, "/s/\1" ,var)
gsub(pat, "/s/\\1" ,var)
gsub(pat, "<s>\\1" ,var)
con <- file("c:/temp/coursework-capstone/final/en_US/en_US.twitter.txt","r")
tw <- readLines(con)
close(con)
head(tw)
gsub(pat, "<s>\\1" ,tw)
pat <-"^[a-z|A-Z|,|.|!]{1,} "
gsub(pat, "<s>\\1" ,tw)
tail(tw)
gsub(pat, "<s>\\1" ,var)
pat <-"^[a-z|A-Z|,|.|!]{1,}"
gsub(pat, "<s>\\1" ,var)
gsub(pat, "<s>\\0" ,var)
gsub(pat, "<s>\\1" ,var)
gsub(pat, "<s>\\2" ,var)
library(stringr)
str_replace(var,pat <s>\\1)
str_replace(var,pat ,"<s>\\1")
str_replace(var,pat ,"<s>")
str_replace(var,pat ,"<s>\1")
str_replace(var,pat ,"<s>\\1")
str_replace(var,pat ,"<s>\\w")
str_replace(var,pat ,"<s>\w")
gsub("[a-z]{3,}" "", "what aaa you taklking about eh")
gsub("[a-z]{3,}", "", "what aaa you taklking about eh")
gsub("[a]{3,}", "", "what aaa you taklking about eh")
gsub("[a\h\b]{3,}", "", "what aaa aha wahta you taklking about eh")
gsub("[a|h|b]{3,}", "", "what aaa aha wahta you taklking about eh")
gsub("[a|h]{3,}","","aaa")
gsub("[a|h]{3,}","","aaaaaa  adsc")
for(i in a-z){print(i)}
for (i in c("a"-"z")){print(i)}
str(a-z)
str(a:z)
str("a":"z")
print(c(a-z))
letters(1:26)
LETTERS
letters
letters[1]
append(letters,LETTERS)
?attr
?table
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
library("markovchain")
library("markovchain")
data <- VCorpus(DirSource("c:/temp/coursework-capstone/samples", encoding = "UTF-8", ignore.case = TRUE), readerControl = list(language = "english"))
#Transform corpus Data
data <- tm_map(data,content_transformer(function(x) iconv(x, to="ASCII", sub=" ")) ) #removes non ascii char
data <- tm_map(data, content_transformer(tolower))      #converts to lower case
data <- tm_map(data, stripWhitespace)                   #removes whitespace
mystopwords <- c("the","for","and","a","but")
data <- tm_map(data, removeWords, words=mystopwords)
data <- tm_map(data, removePunctuation)                 #removes punctuation
data <- tm_map(data, removeNumbers)                     #removes numerics
data <- tm_map(data, stemDocument)
unigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))
tdm <- DocumentTermMatrix(data, control = list(tokenize = unigramTokenizer,wordLengths = c(1, 15)))
head(as.mtarix(tdm))
head(as.matrix(tdm))
sqmx <- createSequenceMatrix(as.matrix(tdm))
head(sqmx)
myfit <- markovchainFit(data=as.matrix(tdm),confidencelevel=.9)
myfit$estimate
rm(myfit)
rm(sqmx)
mkcn <- new("markovchain", states = colnames(as.matrix(tdm),transitionMatrix=as.matrix(tdm)))
colnames(as.matrix(tdm))
mkcn <- new("markovchain", states = colnames(as.matrix(tdm),transitionMatrix=as.matrix(tdm)))
mkcn <- new("markovchain", states = colnames(as.matrix(tdm)),transitionMatrix=as.matrix(tdm))
as.matrix(tdm)[1:4,1:10]
as.matrix(tdm)[1-4,1-10]
unigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 2))
tdm <- DocumentTermMatrix(data, control = list(tokenize = unigramTokenizer,wordLengths = c(1, 15)))
data <- VCorpus(DirSource("c:/temp/coursework-capstone/samples", encoding = "UTF-8", ignore.case = TRUE), readerControl = list(language = "english"))
#Transform corpus Data
data <- tm_map(data,content_transformer(function(x) iconv(x, to="ASCII", sub=" ")) ) #removes non ascii char
data <- tm_map(data, content_transformer(tolower))      #converts to lower case
data <- tm_map(data, stripWhitespace)                   #removes whitespace
mystopwords <- c("the","for","and","a","but")
data <- tm_map(data, removeWords, words=mystopwords)
data <- tm_map(data, removePunctuation)                 #removes punctuation
data <- tm_map(data, removeNumbers)                     #removes numerics
data <- tm_map(data, stemDocument)
tdm <- DocumentTermMatrix(data, control = list(tokenize = unigramTokenizer,wordLengths = c(1, 15)))
mkcn <- new("markovchain", states = colnames(as.matrix(tdm)),transitionMatrix=as.matrix(tdm))
as.matrix(tdm)[1,1]
as.matrix(tdm)[1,]
sqmx <- as.matrix(tdm)
mkcn <- new("markovchain", states = colnames(as.matrix(tdm)),transitionMatrix=sqmx)
fsqmx <- subset(sqmx -1)
mkcn <- new("markovchain", states = colnames(as.matrix(tdm)),transitionMatrix=fsqmx)
mkcn <- new("markovchain", states = colnames(fsqmx),transitionMatrix=fsqmx)
head(colnames(fsqmx))
tail(colnames(fsqmx))
head(colnames(sqmx))
dim(sqmx)
dim(fsqmx)
fsqmx <- subset(sqmx, -1)
?subset
fsqmx <- subset(sqmx, select =-1)
dim(fsqmx)
head(colnames(fsqmx))
as.matrix(tdm)[1-2]
as.matrix(tdm)[1]
as.matrix(tdm)[2]
as.matrix(tdm)[3]
head(colnames(sqmx))
dim(sqmx)
?matrix
smx <- matrix(0,nrow=2,ncol=2)
smx
colnames(smx) <- c(fat,cat)
colnames(smx) <- c("fat","cat")
smx
rownames(smx) <- c("fat","cat")
smx
head(sqmx)
char <- "quick brown fox jumped over the lazy dog and I took the dog home as the brown fox was quick and cruel"
data <- vcorpus(VectorSource(char))
data <- Vcorpus(VectorSource(char))
data <- VCorpus(VectorSource(char))
tdm <- DocumentTermMatrix(data, control = list(tokenize = unigramTokenizer,wordLengths = c(1, 15)))
as.matrix(tdm)
terms(tdm)
createSequenceMatrix(as.matrix(tdm))
as.character(data[[1]])
createSequenceMatrix(as.character(data[[1]]))
length(tdm)
as.matrix(tdm)
class(tdm)
?DocumentTermMatrix
inspect(tdm)
tdm$Terms
colnames(as.matrix(tdm))
numcol(as.matrix(tdm))
colnum(as.matrix(tdm))
colnums(as.matrix(tdm))
rownums(as.matrix(tdm))
ncols(as.matrix(tdm))
nrows(as.matrix(tdm))
nrow(as.matrix(tdm))
ncol(as.matrix(tdm))
sqmx <- (0,nrow=ncol(as.matrix(tdm)),ncol=ncol(as.matrix(tdm)))
sqmx <- matrix(0,nrow=ncol(as.matrix(tdm)),ncol=ncol(as.matrix(tdm)))
sqmx
colnames(sqmx) <- colnames(as.matrix(tdm))
rownames(sqmx) <- colnames(as.matrix(tdm))
sqmx
for(i in rownames(sqmx)){ }
wc("sam")
length(strsplit("sam", " "))
length(strsplit("sam loves me", " "))
length(strsplit("sam loves me", ' '))
length(strsplit("sam loves me", ''))
strsplit("sam loves me", '')
strsplit("sam loves me", ' ')
class(strsplit("sam loves me", ' '))
length(strsplit("sam loves me", ' ')[[1]])
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
Very early observations on the Bills game: Offense still struggling but the
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
shiny::runApp('C:/TEMP/capstone-project')
library(shinyapps)
getwd()
setwd("C:/TEMP/capstone-project")
shinyapps::deployApp('C:/TEMP/capstone-project')
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
